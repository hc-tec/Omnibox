"""
Integrationå±‚å®Œæ•´æµ‹è¯•å¥—ä»¶
åŒ…å«ï¼š
1. DataExecutor æµ‹è¯•
2. CacheService æµ‹è¯•
3. é›†æˆæµ‹è¯•
"""

import sys
import time
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from integration.data_executor import DataExecutor
from integration.cache_service import CacheService, reset_cache_service
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)


def test_executor_cache_integration():
    """æµ‹è¯•DataExecutorä¸CacheServiceçš„é›†æˆ"""
    print("\n" + "="*80)
    print("é›†æˆæµ‹è¯•ï¼šDataExecutor + CacheService")
    print("="*80)

    cache = CacheService()
    executor = DataExecutor()

    try:
        # æµ‹è¯•è·¯å¾„
        test_path = "/hupu/bbs/bxj/1"

        # 1. æ£€æŸ¥ç¼“å­˜ä¸­æ˜¯å¦æœ‰æ•°æ®ï¼ˆåº”è¯¥æ²¡æœ‰ï¼‰
        cached_result = cache.get_rss_cache(test_path)
        assert cached_result is None, "é¦–æ¬¡æµ‹è¯•æ—¶ç¼“å­˜åº”è¯¥ä¸ºç©º"
        print("âœ“ åˆå§‹çŠ¶æ€ï¼šç¼“å­˜ä¸ºç©º")

        # 2. æ‰§è¡Œè¯·æ±‚
        result = executor.fetch_rss(test_path)
        print(f"âœ“ æ‰§è¡Œè¯·æ±‚: {result.status}")

        # 3. å°†ç»“æœå­˜å…¥ç¼“å­˜
        if result.status == "success":
            cache.set_rss_cache(test_path, result)
            print("âœ“ ç»“æœå·²å­˜å…¥ç¼“å­˜")

            # 4. ä»ç¼“å­˜è¯»å–
            cached_result = cache.get_rss_cache(test_path)
            assert cached_result is not None, "ç¼“å­˜åº”è¯¥å­˜åœ¨"
            assert cached_result.status == "success", "ç¼“å­˜ç»“æœçŠ¶æ€åº”è¯¥æ­£ç¡®"
            assert len(cached_result.items) == len(result.items), "ç¼“å­˜æ•°æ®åº”è¯¥å®Œæ•´"
            print(f"âœ“ ä»ç¼“å­˜è¯»å–: {len(cached_result.items)}æ¡æ•°æ®")

            # 5. éªŒè¯ç¼“å­˜å‘½ä¸­ç»Ÿè®¡
            stats = cache.get_stats()
            assert stats['rss_hits'] >= 1, "åº”è¯¥æœ‰ç¼“å­˜å‘½ä¸­"
            print(f"âœ“ ç¼“å­˜ç»Ÿè®¡: å‘½ä¸­ç‡ {stats['rss_hit_rate']:.2%}")

        else:
            print(f"âš ï¸ è¯·æ±‚å¤±è´¥: {result.error_message}")
            print("ç»§ç»­æµ‹è¯•å…¶ä»–åŠŸèƒ½...")

    finally:
        executor.close()


def test_cache_ttl_with_real_data():
    """æµ‹è¯•TTLåœ¨å®é™…æ•°æ®ä¸Šçš„æ•ˆæœ"""
    print("\n" + "="*80)
    print("é›†æˆæµ‹è¯•ï¼šTTLåœ¨å®é™…æ•°æ®ä¸Šçš„æ•ˆæœ")
    print("="*80)

    # ä½¿ç”¨çŸ­TTLè¿›è¡Œæµ‹è¯•
    cache = CacheService(rss_cache_ttl=2)  # 2ç§’TTL
    executor = DataExecutor()

    try:
        test_path = "/bilibili/user/video/2267573"

        # æ‰§è¡Œè¯·æ±‚å¹¶ç¼“å­˜
        result = executor.fetch_rss(test_path)
        if result.status == "success":
            cache.set_rss_cache(test_path, result)
            print(f"âœ“ è¯·æ±‚æ•°æ®å¹¶ç¼“å­˜: {len(result.items)}æ¡")

            # ç«‹å³ä»ç¼“å­˜è·å–
            cached = cache.get_rss_cache(test_path)
            assert cached is not None, "åˆšç¼“å­˜çš„æ•°æ®åº”è¯¥èƒ½è·å–åˆ°"
            print("âœ“ ç«‹å³ä»ç¼“å­˜è·å–æˆåŠŸ")

            # ç­‰å¾…è¿‡æœŸ
            print("ç­‰å¾…2.1ç§’è®©ç¼“å­˜è¿‡æœŸ...")
            time.sleep(2.1)

            # å†æ¬¡è·å–åº”è¯¥å¤±è´¥
            cached = cache.get_rss_cache(test_path)
            assert cached is None, "è¿‡æœŸçš„ç¼“å­˜åº”è¯¥è¢«æ¸…ç†"
            print("âœ“ è¿‡æœŸç¼“å­˜è‡ªåŠ¨æ¸…ç†")
        else:
            print(f"âš ï¸ è¯·æ±‚å¤±è´¥: {result.error_message}")

    finally:
        executor.close()


def test_multiple_sources_caching():
    """æµ‹è¯•ä¸åŒæ•°æ®æºçš„ç¼“å­˜"""
    print("\n" + "="*80)
    print("é›†æˆæµ‹è¯•ï¼šå¤šæ•°æ®æºç¼“å­˜")
    print("="*80)

    cache = CacheService()
    executor = DataExecutor()

    # ä¸åŒæ•°æ®æºçš„æµ‹è¯•è·¯å¾„
    test_paths = [
        "/hupu/bbs/bxj/1",      # è™æ‰‘è®ºå›
        "/bilibili/user/video/2267573",  # Bç«™è§†é¢‘
    ]

    try:
        results = {}

        # åˆ†åˆ«è¯·æ±‚ä¸åŒæ•°æ®æº
        for path in test_paths:
            print(f"\nè¯·æ±‚æ•°æ®æº: {path}")
            result = executor.fetch_rss(path)
            results[path] = result

            if result.status == "success":
                # ç¼“å­˜ç»“æœ
                cache.set_rss_cache(path, result)
                print(f"âœ“ ç¼“å­˜æˆåŠŸ: {result.feed_title} ({len(result.items)}æ¡)")

                # ç«‹å³éªŒè¯ç¼“å­˜
                cached = cache.get_rss_cache(path)
                assert cached is not None, "åˆšç¼“å­˜çš„æ•°æ®åº”è¯¥èƒ½è·å–åˆ°"
                assert cached.feed_title == result.feed_title, "ç¼“å­˜æ ‡é¢˜åº”è¯¥åŒ¹é…"
                print(f"âœ“ ç¼“å­˜éªŒè¯æˆåŠŸ")
            else:
                print(f"âš ï¸ è¯·æ±‚å¤±è´¥: {result.error_message}")

        # éªŒè¯ä¸åŒæ•°æ®æºçš„ç¼“å­˜æ˜¯ç‹¬ç«‹çš„
        cached_data = {}
        for path in test_paths:
            cached = cache.get_rss_cache(path)
            if cached is not None:
                cached_data[path] = cached.feed_title

        print(f"\nâœ“ æˆåŠŸç¼“å­˜äº† {len(cached_data)} ä¸ªæ•°æ®æº:")
        for path, title in cached_data.items():
            print(f"  {path}: {title}")

    finally:
        executor.close()


def test_cache_invalidation():
    """æµ‹è¯•ç¼“å­˜å¤±æ•ˆåŠŸèƒ½"""
    print("\n" + "="*80)
    print("é›†æˆæµ‹è¯•ï¼šç¼“å­˜å¤±æ•ˆ")
    print("="*80)

    cache = CacheService()

    # è®¾ç½®ä¸€äº›æµ‹è¯•ç¼“å­˜
    test_keys = ["/test1", "/test2", "/test3"]
    test_data = {"items": [{"title": f"test item {i}"} for i in range(3)]}

    for key in test_keys:
        cache.set_rss_cache(key, test_data)
        print(f"âœ“ è®¾ç½®ç¼“å­˜: {key}")

    # éªŒè¯ç¼“å­˜å­˜åœ¨
    for key in test_keys:
        cached = cache.get_rss_cache(key)
        assert cached is not None, f"ç¼“å­˜ {key} åº”è¯¥å­˜åœ¨"
        print(f"âœ“ ç¼“å­˜å­˜åœ¨: {key}")

    # å¤±æ•ˆå…¶ä¸­ä¸€ä¸ªç¼“å­˜
    key_to_invalidate = test_keys[1]
    success = cache.invalidate_rss_cache(key_to_invalidate)
    assert success, "ç¼“å­˜å¤±æ•ˆåº”è¯¥æˆåŠŸ"
    print(f"âœ“ ç¼“å­˜å¤±æ•ˆ: {key_to_invalidate}")

    # éªŒè¯å¤±æ•ˆç»“æœ
    cached = cache.get_rss_cache(key_to_invalidate)
    assert cached is None, "å¤±æ•ˆçš„ç¼“å­˜åº”è¯¥ä¸å­˜åœ¨"
    print(f"âœ“ å¤±æ•ˆéªŒè¯: {key_to_invalidate}")

    # éªŒè¯å…¶ä»–ç¼“å­˜ä»ç„¶å­˜åœ¨
    for key in test_keys:
        if key != key_to_invalidate:
            cached = cache.get_rss_cache(key)
            assert cached is not None, f"æœªå¤±æ•ˆçš„ç¼“å­˜ {key} åº”è¯¥å­˜åœ¨"
            print(f"âœ“ æœªå—å½±å“: {key}")

    # å°è¯•å¤±æ•ˆä¸å­˜åœ¨çš„ç¼“å­˜
    success = cache.invalidate_rss_cache("/nonexistent")
    assert not success, "ä¸å­˜åœ¨çš„ç¼“å­˜å¤±æ•ˆåº”è¯¥è¿”å›False"
    print("âœ“ ä¸å­˜åœ¨ç¼“å­˜çš„å¤±æ•ˆæ“ä½œæ­£ç¡®")


def test_error_handling_with_cache():
    """æµ‹è¯•é”™è¯¯å¤„ç†ä¸ç¼“å­˜çš„ç»“åˆ"""
    print("\n" + "="*80)
    print("é›†æˆæµ‹è¯•ï¼šé”™è¯¯å¤„ç†ä¸ç¼“å­˜")
    print("="*80)

    cache = CacheService()
    executor = DataExecutor()

    try:
        # 1. æµ‹è¯•æ— æ•ˆè·¯å¾„çš„ç¼“å­˜å¤„ç†
        invalid_path = "/invalid/nonexistent/path"
        result = executor.fetch_rss(invalid_path)

        print(f"æ— æ•ˆè·¯å¾„è¯·æ±‚ç»“æœ: {result.status}")
        if result.status == "error":
            # ä¸ç¼“å­˜é”™è¯¯ç»“æœï¼ˆè¿™æ˜¯ç­–ç•¥é€‰æ‹©ï¼‰
            print("âœ“ é”™è¯¯ç»“æœä¸ç¼“å­˜")

            # éªŒè¯ç¼“å­˜ä¸­æ²¡æœ‰é”™è¯¯ç»“æœ
            cached = cache.get_rss_cache(invalid_path)
            assert cached is None, "é”™è¯¯ç»“æœä¸åº”è¯¥è¢«ç¼“å­˜"
            print("âœ“ é”™è¯¯ç»“æœæœªè¢«ç¼“å­˜")

        # 2. æµ‹è¯•ç½‘ç»œé”™è¯¯ï¼ˆé€šè¿‡ä¸å­˜åœ¨çš„åœ°å€æ¨¡æ‹Ÿï¼‰
        # æ³¨æ„ï¼šè¿™ä¸ªæµ‹è¯•å¯èƒ½ä¼šæ¯”è¾ƒæ…¢ï¼Œå› ä¸ºéœ€è¦ç­‰å¾…è¶…æ—¶
        print("\næµ‹è¯•ç½‘ç»œè¶…æ—¶å¤„ç†...")
        original_timeout = executor.request_timeout
        executor.request_timeout = 1  # 1ç§’è¶…æ—¶

        # ä½¿ç”¨ä¸€ä¸ªå¯èƒ½ä¸å­˜åœ¨çš„åœ°å€
        result = executor.fetch_rss("/test/timeout")
        print(f"è¶…æ—¶æµ‹è¯•ç»“æœ: {result.status}")

        executor.request_timeout = original_timeout  # æ¢å¤è¶…æ—¶è®¾ç½®

    finally:
        executor.close()


def test_performance_with_cache():
    """æµ‹è¯•ç¼“å­˜çš„æ€§èƒ½æå‡"""
    print("\n" + "="*80)
    print("é›†æˆæµ‹è¯•ï¼šç¼“å­˜æ€§èƒ½æå‡")
    print("="*80)

    cache = CacheService()
    executor = DataExecutor()

    try:
        test_path = "/hupu/bbs/bxj/1"

        # 1. ç¬¬ä¸€æ¬¡è¯·æ±‚ï¼ˆæ— ç¼“å­˜ï¼‰
        start_time = time.time()
        result1 = executor.fetch_rss(test_path)
        first_request_time = time.time() - start_time

        if result1.status == "success":
            print(f"âœ“ ç¬¬ä¸€æ¬¡è¯·æ±‚è€—æ—¶: {first_request_time:.3f}ç§’")

            # ç¼“å­˜ç»“æœ
            cache.set_rss_cache(test_path, result1)

            # 2. ç¬¬äºŒæ¬¡è¯·æ±‚ï¼ˆä»ç¼“å­˜ï¼‰
            start_time = time.time()
            result2 = cache.get_rss_cache(test_path)
            cache_request_time = time.time() - start_time

            print(f"âœ“ ç¼“å­˜è¯·æ±‚è€—æ—¶: {cache_request_time:.3f}ç§’")

            # 3. æ€§èƒ½æ¯”è¾ƒ
            if cache_request_time > 0:
                speedup = first_request_time / cache_request_time
                print(f"âœ“ ç¼“å­˜åŠ é€Ÿæ¯”: {speedup:.1f}x")

                # ç¼“å­˜åº”è¯¥æ˜æ˜¾æ›´å¿«
                assert speedup > 10, f"ç¼“å­˜åº”è¯¥æ˜¾è‘—æ›´å¿«ï¼Œä½†åªåŠ é€Ÿäº† {speedup:.1f}x"
                print("âœ“ æ€§èƒ½æå‡éªŒè¯é€šè¿‡")
            else:
                print("âš ï¸ ç¼“å­˜è¯·æ±‚å¤ªå¿«ï¼Œæ— æ³•å‡†ç¡®æµ‹é‡")

            # 4. éªŒè¯æ•°æ®ä¸€è‡´æ€§
            assert result2.items == result1.items, "ç¼“å­˜æ•°æ®åº”è¯¥ä¸åŸå§‹æ•°æ®ä¸€è‡´"
            assert result2.feed_title == result1.feed_title, "ç¼“å­˜æ ‡é¢˜åº”è¯¥ä¸€è‡´"
            print("âœ“ æ•°æ®ä¸€è‡´æ€§éªŒè¯é€šè¿‡")

        else:
            print(f"âš ï¸ ç¬¬ä¸€æ¬¡è¯·æ±‚å¤±è´¥: {result1.error_message}")

    finally:
        executor.close()


def main():
    """ä¸»å‡½æ•°"""
    print("="*80)
    print("Integrationå±‚å®Œæ•´æµ‹è¯•å¥—ä»¶")
    print("="*80)

    try:
        # é‡ç½®ç¼“å­˜çŠ¶æ€
        reset_cache_service()

        # é›†æˆæµ‹è¯•
        test_executor_cache_integration()
        test_cache_ttl_with_real_data()
        test_multiple_sources_caching()
        test_cache_invalidation()
        test_error_handling_with_cache()
        test_performance_with_cache()

        print("\n" + "="*80)
        print("ğŸ‰ æ‰€æœ‰é›†æˆæµ‹è¯•é€šè¿‡ï¼")
        print("="*80)

    except Exception as e:
        print(f"\nâŒ é›†æˆæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
